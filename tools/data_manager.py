#!/usr/bin/env python3
"""
æ•°æ®ç®¡ç†å·¥å…·
ç”¨äºç®¡ç†datasetsç›®å½•ä¸­çš„æ•°æ®æ–‡ä»¶
"""

import os
import sys
import pandas as pd
from datetime import datetime, timedelta
import glob

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class DataManager:
    """æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.datasets_dir = os.path.join(self.project_root, 'datasets')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for subdir in ['raw', 'processed', 'analysis']:
            os.makedirs(os.path.join(self.datasets_dir, subdir), exist_ok=True)
    
    def list_data_files(self, data_type: str = None):
        """
        åˆ—å‡ºæ•°æ®æ–‡ä»¶
        
        Args:
            data_type: æ•°æ®ç±»å‹ ('raw', 'processed', 'analysis') æˆ– None (å…¨éƒ¨)
        """
        print("ğŸ“‚ æ•°æ®æ–‡ä»¶åˆ—è¡¨")
        print("=" * 60)
        
        if data_type:
            directories = [data_type]
        else:
            directories = ['raw', 'processed', 'analysis']
        
        total_files = 0
        total_size = 0
        
        for dir_name in directories:
            dir_path = os.path.join(self.datasets_dir, dir_name)
            if not os.path.exists(dir_path):
                continue
                
            files = glob.glob(os.path.join(dir_path, '*.csv'))
            
            if files:
                print(f"\nğŸ“ {dir_name.upper()}/ ({len(files)} ä¸ªæ–‡ä»¶)")
                print("-" * 40)
                
                for file_path in sorted(files):
                    filename = os.path.basename(file_path)
                    file_size = os.path.getsize(file_path)
                    mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    
                    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                    if file_size < 1024:
                        size_str = f"{file_size}B"
                    elif file_size < 1024 * 1024:
                        size_str = f"{file_size/1024:.1f}KB"
                    else:
                        size_str = f"{file_size/(1024*1024):.1f}MB"
                    
                    print(f"  {filename:<40} {size_str:>8} {mod_time.strftime('%Y-%m-%d %H:%M')}")
                    
                    total_files += 1
                    total_size += file_size
            else:
                print(f"\nğŸ“ {dir_name.upper()}/ (ç©º)")
        
        # æ€»è®¡
        if total_size < 1024 * 1024:
            total_size_str = f"{total_size/1024:.1f}KB"
        else:
            total_size_str = f"{total_size/(1024*1024):.1f}MB"
        
        print(f"\nğŸ“Š æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶, {total_size_str}")
    
    def get_file_info(self, filename: str):
        """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
        file_found = False
        
        for dir_name in ['raw', 'processed', 'analysis']:
            file_path = os.path.join(self.datasets_dir, dir_name, filename)
            if os.path.exists(file_path):
                file_found = True
                print(f"ğŸ“„ æ–‡ä»¶ä¿¡æ¯: {filename}")
                print("=" * 50)
                print(f"ä½ç½®: datasets/{dir_name}/{filename}")
                print(f"å¤§å°: {os.path.getsize(file_path):,} å­—èŠ‚")
                print(f"ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(file_path))}")
                
                # å°è¯•è¯»å–CSVå¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                try:
                    df = pd.read_csv(file_path)
                    print(f"æ•°æ®è¡Œæ•°: {len(df):,}")
                    print(f"æ•°æ®åˆ—æ•°: {len(df.columns)}")
                    print(f"åˆ—å: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}")
                    
                    if 'datetime' in df.columns:
                        df['datetime'] = pd.to_datetime(df['datetime'])
                        print(f"æ—¶é—´èŒƒå›´: {df['datetime'].min()} åˆ° {df['datetime'].max()}")
                    
                    print(f"\nå‰5è¡Œæ•°æ®:")
                    print(df.head().to_string())
                    
                except Exception as e:
                    print(f"è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
                
                break
        
        if not file_found:
            print(f"âŒ æ–‡ä»¶ {filename} æœªæ‰¾åˆ°")
    
    def clean_old_files(self, days: int = 7):
        """æ¸…ç†æ—§æ–‡ä»¶"""
        cutoff_date = datetime.now() - timedelta(days=days)
        deleted_files = []
        
        for dir_name in ['raw', 'processed', 'analysis']:
            dir_path = os.path.join(self.datasets_dir, dir_name)
            if not os.path.exists(dir_path):
                continue
            
            files = glob.glob(os.path.join(dir_path, '*.csv'))
            
            for file_path in files:
                mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                if mod_time < cutoff_date:
                    filename = os.path.basename(file_path)
                    os.remove(file_path)
                    deleted_files.append(f"{dir_name}/{filename}")
        
        if deleted_files:
            print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {len(deleted_files)} ä¸ªè¶…è¿‡ {days} å¤©çš„æ–‡ä»¶:")
            for file in deleted_files:
                print(f"  - {file}")
        else:
            print(f"âœ… æ²¡æœ‰è¶…è¿‡ {days} å¤©çš„æ–‡ä»¶éœ€è¦æ¸…ç†")
    
    def backup_data(self, backup_dir: str = None):
        """å¤‡ä»½æ•°æ®"""
        if not backup_dir:
            backup_dir = os.path.join(self.project_root, 'backup', datetime.now().strftime('%Y%m%d_%H%M%S'))
        
        os.makedirs(backup_dir, exist_ok=True)
        
        import shutil
        
        try:
            shutil.copytree(self.datasets_dir, os.path.join(backup_dir, 'datasets'))
            print(f"âœ… æ•°æ®å·²å¤‡ä»½åˆ°: {backup_dir}")
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
    
    def show_stats(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡")
        print("=" * 40)
        
        stats = {}
        
        for dir_name in ['raw', 'processed', 'analysis']:
            dir_path = os.path.join(self.datasets_dir, dir_name)
            if os.path.exists(dir_path):
                files = glob.glob(os.path.join(dir_path, '*.csv'))
                total_size = sum(os.path.getsize(f) for f in files)
                stats[dir_name] = {
                    'files': len(files),
                    'size': total_size
                }
        
        for dir_name, stat in stats.items():
            size_mb = stat['size'] / (1024 * 1024)
            print(f"{dir_name.upper():>10}: {stat['files']:>3} æ–‡ä»¶, {size_mb:>6.1f}MB")
        
        total_files = sum(s['files'] for s in stats.values())
        total_size = sum(s['size'] for s in stats.values()) / (1024 * 1024)
        print(f"{'æ€»è®¡':>10}: {total_files:>3} æ–‡ä»¶, {total_size:>6.1f}MB")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®ç®¡ç†å·¥å…·')
    parser.add_argument('--list', '-l', nargs='?', const='all', 
                       choices=['raw', 'processed', 'analysis', 'all'], 
                       help='åˆ—å‡ºæ•°æ®æ–‡ä»¶ (é»˜è®¤: all)')
    parser.add_argument('--info', '-i', type=str, help='æ˜¾ç¤ºæ–‡ä»¶è¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--clean', '-c', nargs='?', const=7, type=int, 
                       help='æ¸…ç†Nå¤©å‰çš„æ–‡ä»¶ (é»˜è®¤7å¤©)')
    parser.add_argument('--backup', '-b', nargs='?', const=None, type=str, 
                       help='å¤‡ä»½æ•°æ®åˆ°æŒ‡å®šç›®å½•')
    parser.add_argument('--stats', '-s', action='store_true', help='æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡')
    
    args = parser.parse_args()
    
    dm = DataManager()
    
    if args.list is not None:
        list_type = None if args.list == 'all' else args.list
        dm.list_data_files(list_type)
    elif args.info:
        dm.get_file_info(args.info)
    elif args.clean is not None:
        dm.clean_old_files(args.clean)
    elif args.backup is not None:
        dm.backup_data(args.backup)
    elif args.stats:
        dm.show_stats()
    else:
        # é»˜è®¤æ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
        dm.list_data_files()

if __name__ == "__main__":
    main()
